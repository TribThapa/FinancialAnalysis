{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cc8f18",
   "metadata": {},
   "source": [
    "### Description: This program uses an articifical neural network called Long Short Term Memory (LSTM) to predict the closing stock price using the past 60-day stock price.\n",
    "\n",
    "### LSTM: is an artificial recurring neural network architecture used in the field of deep learning. \n",
    "- Unlike standard feed-forward neural networks, LSTM has feedback connections. \n",
    "- It can not only process single data-points such as images but also entire sequences of data such as speech or video.\n",
    "- Are generally used for sequence prediction problems\n",
    "- They work so well because the system is able to store past information that is important and discard information that is not important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660576b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import math\n",
    "import pandas_datareader as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c5809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock data\n",
    "df = web.DataReader(\"AAPL\", \n",
    "                    data_source=\"yahoo\",\n",
    "                    start=\"2018-01-01\",\n",
    "                    end=\"2021-06-18\")\n",
    "\n",
    "#Show the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb713dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numnber of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38eb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the closeing price history\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.title('Close Price History')\n",
    "plt.plot(df[\"Close\"])\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD $', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178fb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the close prices\n",
    "data = df.filter([\"Close\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data frame to a numpy array\n",
    "dataset = data.values\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of rows to train model. Train it on 80% of the data.\n",
    "training_data_len = math.ceil(len(dataset) * 0.8)\n",
    "training_data_len\n",
    "\n",
    "#Check it is 80% of the data by multiplying 0.8 * 872 i.e., the no. of rows in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data to normalise the data i.e., here we're scaling our closing prices to be between values 0 and 1 with weighting based upon their current close price.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "#scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training dataset \n",
    "\n",
    "#Create the scaled training dataset\n",
    "train_data = scaled_data[0:training_data_len, :]\n",
    "#train_data[60:70]\n",
    "\n",
    "#Split the data into x_train and y_train datasets\n",
    "x_train = [] #training set\n",
    "y_train = [] #target variable\n",
    "      \n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    \n",
    "#     if i <= 61:\n",
    "#         print(x_train) #containes the past 60 values\n",
    "#         print(y_train) #the value we want to predict i.e, the 61st value onwards\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a3583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x_train and y_train to numpy array to train the LSTM model\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c6716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for the LSTM model which requries a 3-dim \n",
    "x_train.shape #need to convert to 3 dimensional\n",
    "\n",
    "x_train = np.reshape(x_train,(x_train.shape[0], x_train.shape[1], 1)) # number of rows: 638; number of time-stamps: 60 (get from .shape); number of features: closing price\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0418aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model. An optimizer is used to improve upon the loss function, and the loss function is used to measure how well the model did on training. \n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56585bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using fit (another name for train).\n",
    "model.fit(x_train, #what you're using to predict\n",
    "          y_train, # what you want to predict\n",
    "          batch_size=1, #total number of training samples present in one batch\n",
    "          epochs=1) # number of interatiosn past forward and backward a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a657913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the testing dataset\n",
    "\n",
    "# Create a new array containing scaled values from index \n",
    "test_data = scaled_data[training_data_len-60:, :]\n",
    "\n",
    "# Create test datasets\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len :, :] #all values we want our model to predict \n",
    "\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab770d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to a numpy array \n",
    "x_test = np.array(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to 3-dimensional \n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb118a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model's predicted price values\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root mean squared error to evaluate the model\n",
    "# rmse is a good measure of how accurate the model predicts the response, is the std dev of the residuals, and lower values = better fit\n",
    "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
    "rmse #Closer to 0 the predictions were perfect, and the model got the right values from the testing data i.e., the values in y_test and predictions are very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "train = data[0:training_data_len] #dataset on which the model was trained on\n",
    "valid = data[training_data_len:] #actual close price values for those days\n",
    "valid[\"Predictions\"] = predictions #predicted close prices\n",
    "\n",
    "#Visualise the data\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Model\")\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"Close Price USD($)\", fontsize=18)\n",
    "plt.plot(train[\"Close\"])\n",
    "plt.plot(valid[[\"Close\", \"Predictions\"]])\n",
    "plt.legend([\"Train\", \"Val\", \"Predictions\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the valid (actual) and predicted prices\n",
    "valid.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d47e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get quote\n",
    "apple_quote = web.DataReader(\"AAPL\",\n",
    "                             data_source=\"yahoo\",\n",
    "                             start=\"2018-01-01\",\n",
    "                             end=\"2020-12-17\")\n",
    "\n",
    "# Create new df\n",
    "new_df = apple_quote.filter([\"Close\"])\n",
    "\n",
    "# Get last 60-days closing price and convert to array\n",
    "last_60_days = new_df[-60:].values\n",
    "\n",
    "# Scale data to be values between 0-1\n",
    "last_60_days_scaled = scaler.transform(last_60_days)\n",
    "\n",
    "# Create empty list\n",
    "X_test = []\n",
    "\n",
    "# Append past 60-days to X_test\n",
    "X_test.append(last_60_days_scaled)\n",
    "\n",
    "# Convert X_test to a numpy array\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Reshape\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Get predicted scaled price\n",
    "pred_price = model.predict(X_test)\n",
    "\n",
    "# Undo scaling\n",
    "pred_price = scaler.inverse_transform(pred_price)\n",
    "pred_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_quote2 = web.DataReader(\"AAPL\",\n",
    "                              data_source=\"yahoo\",\n",
    "                              start=\"2020-12-18\",\n",
    "                              end=\"2020-12-18\")\n",
    "\n",
    "print(apple_quote2[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe14763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
